Ref: 
- [Cornell CS 5787: Applied Machine Learning. Lecture 11. Part 1: The Kernel Trick (Intuition)](https://www.youtube.com/watch?v=Cjvg7nhb2dk&list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83&index=41)
- [Cornell CS 5787: Applied Machine Learning. Lecture 11. Part 2: The Kernel Trick (Example)](https://www.youtube.com/watch?v=41a6ayyWOWM&list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83&index=42)
- [Cornell CS 5787: Applied Machine Learning. Lecture 11. Part 3: The Kernel Trick in SVMs](https://www.youtube.com/watch?v=16nF6g7C4q8&list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83&index=43)
- [Cornell CS 5787: Applied Machine Learning. Lecture 11. Part 4: Types of Kernels](https://www.youtube.com/watch?v=16nF6g7C4q8&list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83&index=44)

==Kernel Trick==:
- Calculating the high dimensional relationships ==without actually transforming== the data to higher dimensions, 
is called the Kernel Trick
- Reduces amount of computation required for SVM by ==avoiding the math== that transforms the data from low to high dimensions